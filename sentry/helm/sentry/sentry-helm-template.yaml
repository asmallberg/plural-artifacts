---
# Source: sentry/charts/clickhouse/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-clickhouse
  labels:
    helm.sh/chart: clickhouse-0.1.2
    app.kubernetes.io/name: clickhouse
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "22.8.11.15"
    app.kubernetes.io/managed-by: Helm
---
# Source: sentry/charts/sentry/templates/serviceaccount-metrics.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-metrics
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-relay.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-relay
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-billing-metrics-consumer.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-billing-metrics-consumer
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-cron.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-cron
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-ingest-consumer.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-ingest-consumer
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-ingest-metrics-consumer-perf.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-ingest-metrics-consumer-perf
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-ingest-metrics-consumer-rh.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-ingest-metrics-consumer-rh
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-ingest-replay-recordings.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-ingest-replay-recordings
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-post-process-forwarder-errors.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-post-process-forwarder-errors
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-post-process-forwarder-transactions.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-post-process-forwarder-transactions
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-subscription-consumer-events.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-subscription-consumer-events
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-subscription-consumer-transactions.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-subscription-consumer-transactions
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-web.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-web
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-sentry-worker.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-worker
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-snuba.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-snuba
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/serviceaccount-symbolicator.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sentry-symbolicator-api
automountServiceAccountToken: true
---
# Source: sentry/charts/sentry/templates/secret-snuba-env.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-sentry-snuba-env
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
type: Opaque
data:
  CLICKHOUSE_PORT: "OTAwMA=="
  CLICKHOUSE_DATABASE: "c2VudHJ5"
  CLICKHOUSE_USER: "YWRtaW4="
  CLICKHOUSE_PASSWORD: "Y2hhbmdlX21l"
---
# Source: sentry/templates/sentry-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: sentry-system-secret
  labels:
    helm.sh/chart: sentry-0.2.16
    app.kubernetes.io/name: sentry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "23.5.0"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  key:
---
# Source: sentry/charts/sentry/templates/configmap-memcached.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-sentry-memcached
data:
  MEMCACHED_MEMORY_LIMIT: "2048"
  MEMCACHED_MAX_ITEM_SIZE: "26214400"
---
# Source: sentry/charts/sentry/templates/configmap-relay.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-sentry-relay
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
data:
  config.yml: |-
    relay:
      mode: managed
      upstream: "http://release-name-sentry-web:9000/"
      host: 0.0.0.0
      port: 3000

    processing:
      enabled: true

      kafka_config:
        - name: "bootstrap.servers"
          value: "kafka-kafka-bootstrap.kafka:9092"
        - name: "message.max.bytes"
          value: 50000000  # 50MB or bust
      redis: "redis://redis-master.redis:6379"
      topics:
        metrics_transactions: ingest-performance-metrics
        metrics_sessions: ingest-metrics

    # No YAML relay config given
---
# Source: sentry/charts/sentry/templates/configmap-sentry.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-sentry-sentry
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
data:
  config.yml: |-

    # This URL will be used to tell Symbolicator where to obtain the Sentry source.
    # See https://getsentry.github.io/symbolicator/api/
    system.internal-url-prefix: 'http://release-name-sentry-web:9000'
    symbolicator.enabled: false

    ##########
    # Github #
    ##########

    ##########
    # Google #
    ##########

    #########
    # Slack #
    #########

    #########
    # Redis #
    #########
    redis.clusters:
      default:
        hosts:
          0:
            host: "redis-master.redis"
            port: 6379

    ################
    # File storage #
    ################
    # Uploaded media uses these `filestore` settings. The available
    # backends are either `filesystem` or `s3`.
    filestore.backend: "filesystem"
    filestore.options:
      location: "/var/lib/sentry/files"
    
  sentry.conf.py: |-
    from sentry.conf.server import *  # NOQA
    from distutils.util import strtobool

    BYTE_MULTIPLIER = 1024
    UNITS = ("K", "M", "G")
    def unit_text_to_bytes(text):
        unit = text[-1].upper()
        power = UNITS.index(unit) + 1
        return float(text[:-1])*(BYTE_MULTIPLIER**power)

    DATABASES = {
        "default": {
            "ENGINE": "sentry.db.postgres",
            "NAME": "sentry",
            "USER": "sentry",
            "PASSWORD": os.environ.get("POSTGRES_PASSWORD", ""),
            "HOST": "plural-sentry",
            "PORT": 5432,
            'OPTIONS': {
                'sslmode': 'require',
            },
        }
    }

    # You should not change this setting after your database has been created
    # unless you have altered all schemas first
    SENTRY_USE_BIG_INTS = True

    ###########
    # General #
    ###########


    secret_key = env('SENTRY_SECRET_KEY')
    if not secret_key:
      raise Exception('Error: SENTRY_SECRET_KEY is undefined')

    SENTRY_OPTIONS['system.secret-key'] = secret_key

    # Instruct Sentry that this install intends to be run by a single organization
    # and thus various UI optimizations should be enabled.
    SENTRY_SINGLE_ORGANIZATION = True

    SENTRY_OPTIONS["system.event-retention-days"] = int(env('SENTRY_EVENT_RETENTION_DAYS') or "90")

    #########
    # Queue #
    #########

    # See https://docs.getsentry.com/on-premise/server/queue/ for more
    # information on configuring your queue broker and workers. Sentry relies
    # on a Python framework called Celery to manage queues.
    BROKER_URL = os.environ.get("BROKER_URL", "amqp://guest:guest@rabbitmq.rabbitmq:5672/sentry")

    #########
    # Cache #
    #########

    # Sentry currently utilizes two separate mechanisms. While CACHES is not a
    # requirement, it will optimize several high throughput patterns.

    # CACHES = {
    #     "default": {
    #         "BACKEND": "django.core.cache.backends.memcached.MemcachedCache",
    #         "LOCATION": ["memcached:11211"],
    #         "TIMEOUT": 3600,
    #     }
    # }

    # A primary cache is required for things such as processing events
    SENTRY_CACHE = "sentry.cache.redis.RedisCache"

    DEFAULT_KAFKA_OPTIONS = {
        "bootstrap.servers": "kafka-kafka-bootstrap.kafka:9092",
        "message.max.bytes": 50000000,
        "socket.timeout.ms": 1000,
    }

    SENTRY_EVENTSTREAM = "sentry.eventstream.kafka.KafkaEventStream"
    SENTRY_EVENTSTREAM_OPTIONS = {"producer_configuration": DEFAULT_KAFKA_OPTIONS}

    KAFKA_CLUSTERS["default"] = DEFAULT_KAFKA_OPTIONS

    ###############
    # Rate Limits #
    ###############

    # Rate limits apply to notification handlers and are enforced per-project
    # automatically.

    SENTRY_RATELIMITER = "sentry.ratelimits.redis.RedisRateLimiter"

    ##################
    # Update Buffers #
    ##################

    # Buffers (combined with queueing) act as an intermediate layer between the
    # database and the storage API. They will greatly improve efficiency on large
    # numbers of the same events being sent to the API in a short amount of time.
    # (read: if you send any kind of real data to Sentry, you should enable buffers)

    SENTRY_BUFFER = "sentry.buffer.redis.RedisBuffer"

    ##########
    # Quotas #
    ##########

    # Quotas allow you to rate limit individual projects or the Sentry install as
    # a whole.

    SENTRY_QUOTAS = "sentry.quotas.redis.RedisQuota"

    ########
    # TSDB #
    ########

    # The TSDB is used for building charts as well as making things like per-rate
    # alerts possible.

    SENTRY_TSDB = "sentry.tsdb.redissnuba.RedisSnubaTSDB"

    #########
    # SNUBA #
    #########

    SENTRY_SEARCH = "sentry.search.snuba.EventsDatasetSnubaSearchBackend"
    SENTRY_SEARCH_OPTIONS = {}
    SENTRY_TAGSTORE_OPTIONS = {}

    ###########
    # Digests #
    ###########

    # The digest backend powers notification summaries.

    SENTRY_DIGESTS = "sentry.digests.backends.redis.RedisBackend"

    ##############
    # Web Server #
    ##############

    SENTRY_WEB_HOST = "0.0.0.0"
    SENTRY_WEB_PORT = 9000
    SENTRY_PUBLIC = False
    SENTRY_WEB_OPTIONS = {
        "http": "%s:%s" % (SENTRY_WEB_HOST, SENTRY_WEB_PORT),
        "protocol": "uwsgi",
        # This is needed to prevent https://git.io/fj7Lw
        "uwsgi-socket": None,
        # Keep this between 15s-75s as that's what Relay supports
        "http-keepalive": 15,
        "http-chunked-input": True,
        # the number of web workers
        'workers': 3,
        # Turn off memory reporting
        "memory-report": False,
        # Some stuff so uwsgi will cycle workers sensibly
        'max-requests': 100000,
        'max-requests-delta': 500,
        'max-worker-lifetime': 86400,
        # Duplicate options from sentry default just so we don't get
        # bit by sentry changing a default value that we depend on.
        'thunder-lock': True,
        'log-x-forwarded-for': False,
        'buffer-size': 32768,
        'limit-post': 209715200,
        'disable-logging': True,
        'reload-on-rss': 600,
        'ignore-sigpipe': True,
        'ignore-write-errors': True,
        'disable-write-exception': True,
    }

    ###########
    # SSL/TLS #
    ###########

    # If you're using a reverse SSL proxy, you should enable the X-Forwarded-Proto
    # header and enable the settings below

    # SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')
    # SESSION_COOKIE_SECURE = True
    # CSRF_COOKIE_SECURE = True
    # SOCIAL_AUTH_REDIRECT_IS_HTTPS = True

    # End of SSL/TLS settings

    ############
    # Features #
    ############


    SENTRY_FEATURES = {
      "auth:register": True
    }
    SENTRY_FEATURES["projects:sample-events"] = False
    SENTRY_FEATURES.update(
        {
            feature: True
            for feature in ("organizations:advanced-search",
                "organizations:android-mappings",
                "organizations:api-keys",
                "organizations:boolean-search",
                "organizations:related-events",
                "organizations:alert-filters",
                "organizations:custom-symbol-sources",
                "organizations:dashboards-basic",
                "organizations:dashboards-edit",
                "organizations:data-forwarding",
                "organizations:discover",
                "organizations:discover-basic",
                "organizations:discover-query",
                "organizations:discover-frontend-use-events-endpoint",
                "organizations:enterprise-perf",
                "organizations:event-attachments",
                "organizations:events",
                "organizations:global-views",
                "organizations:incidents",
                "organizations:metric-alert-builder-aggregate",
                "organizations:metric-alert-gui-filters",
                "organizations:integrations-event-hooks",
                "organizations:integrations-issue-basic",
                "organizations:integrations-issue-sync",
                "organizations:integrations-alert-rule",
                "organizations:integrations-chat-unfurl",
                "organizations:integrations-incident-management",
                "organizations:integrations-ticket-rules",
                "organizations:integrations-vsts-limited-scopes",
                "organizations:integrations-stacktrace-link",
                "organizations:internal-catchall",
                "organizations:invite-members",
                "organizations:large-debug-files",
                "organizations:monitors",
                "organizations:onboarding",
                "organizations:org-saved-searches",
                "organizations:performance-view",
                "organizations:performance-frontend-use-events-endpoint",
                "organizations:project-detail",
                "organizations:relay",
                "organizations:release-performance-views",
                "organizations:rule-page",
                "organizations:set-grouping-config",
                "organizations:custom-event-title",
                "organizations:slack-migration",
                "organizations:sso-basic",
                "organizations:sso-rippling",
                "organizations:sso-saml2",
                "organizations:sso-migration",
                "organizations:stacktrace-hover-preview",
                "organizations:symbol-sources",
                "organizations:transaction-comparison",
                "organizations:usage-stats-graph",
                "organizations:inbox",
                "organizations:unhandled-issue-flag",
                "organizations:invite-members-rate-limits",
                "organizations:dashboards-v2",
                "organizations:reprocessing-v2",
                "organizations:metrics",
                "organizations:metrics-extraction",
                "organizations:transaction-metrics-extraction",
                "organizations:session-replay",

                "projects:alert-filters",
                "projects:custom-inbound-filters",
                "projects:data-forwarding",
                "projects:discard-groups",
                "projects:issue-alerts-targeting",
                "projects:minidump",
                "projects:rate-limits",
                "projects:sample-events",
                "projects:servicehooks",
                "projects:similarity-view",
                "projects:similarity-indexing",
                "projects:similarity-view-v2",
                "projects:similarity-indexing-v2",

                "projects:plugins",
            )
        }
    )

    #######################
    # Email Configuration #
    #######################
    SENTRY_OPTIONS['mail.backend'] = os.getenv("SENTRY_EMAIL_BACKEND", "dummy")
    SENTRY_OPTIONS['mail.use-tls'] = bool(strtobool(os.getenv("SENTRY_EMAIL_USE_TLS", "false")))
    SENTRY_OPTIONS['mail.use-ssl'] = bool(strtobool(os.getenv("SENTRY_EMAIL_USE_SSL", "false")))
    SENTRY_OPTIONS['mail.username'] = os.getenv("SENTRY_EMAIL_USERNAME", "")
    SENTRY_OPTIONS['mail.password'] = os.getenv("SENTRY_EMAIL_PASSWORD", "")
    SENTRY_OPTIONS['mail.port'] = int(os.getenv("SENTRY_EMAIL_PORT", "25"))
    SENTRY_OPTIONS['mail.host'] = os.getenv("SENTRY_EMAIL_HOST", "")
    SENTRY_OPTIONS['mail.from'] = os.getenv("SENTRY_EMAIL_FROM", "")

    #########################
    # Bitbucket Integration #
    #########################

    # BITBUCKET_CONSUMER_KEY = 'YOUR_BITBUCKET_CONSUMER_KEY'
    # BITBUCKET_CONSUMER_SECRET = 'YOUR_BITBUCKET_CONSUMER_SECRET'

    #########
    # Relay #
    #########
    SENTRY_RELAY_WHITELIST_PK = []
    SENTRY_RELAY_OPEN_REGISTRATION = True

    #######################
    # OpenAi Suggestions #
    #######################
    
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
    if OPENAI_API_KEY:
      SENTRY_FEATURES["organizations:open-ai-suggestion"] = True
    SENTRY_METRICS_BACKEND = 'sentry.metrics.statsd.StatsdMetricsBackend'
    SENTRY_METRICS_OPTIONS = {
        'host': 'release-name-sentry-metrics',
        'port': 9125,
    }
    # No Python Extension Config Given
---
# Source: sentry/charts/sentry/templates/configmap-snuba.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-sentry-snuba
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
data:
  settings.py: |
    import os

    from snuba.settings import *

    env = os.environ.get

    DEBUG = env("DEBUG", "0").lower() in ("1", "true")

    # Clickhouse Options
    CLUSTERS = [
      {
        "host": env("CLICKHOUSE_HOST", "service-sentry-clickhouse"),
        "port": int(9000),
        "user":  env("CLICKHOUSE_USER", "default"),
        "password": env("CLICKHOUSE_PASSWORD", ""),
        "database": env("CLICKHOUSE_DATABASE", "default"),
        "http_port": 8123,
        "storage_sets": {
            "cdc",
            "discover",
            "events",
            "events_ro",
            "metrics",
            "migrations",
            "outcomes",
            "querylog",
            "sessions",
            "transactions",
            "profiles",
            "functions",
            "replays",
            "generic_metrics_sets",
            "generic_metrics_distributions",
            "search_issues",
            "generic_metrics_counters",
            "spans",
        },
        "single_node": False,
        "cluster_name": "sentry",
        "distributed_cluster_name": "sentry",
      },
    ]

    # Redis Options
    REDIS_HOST = "redis-master.redis"
    REDIS_PORT = 6379
    REDIS_DB = int(env("REDIS_DB", 1))
    DOGSTATSD_HOST = "release-name-sentry-metrics"
    DOGSTATSD_PORT = 9125

    # No Python Extension Config Given
---
# Source: sentry/templates/monitoring/dashboards/sentry-dashboard.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sentry-issues-events-overview-dashboard
  labels: 
    helm.sh/chart: sentry-0.2.16
    app.kubernetes.io/name: sentry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "23.5.0"
    app.kubernetes.io/managed-by: Helm
    grafana_dashboard: sentry-issues-events-overview
  annotations:
    k8s-sidecar-target-directory: /tmp/dashboards/Sentry Dashboards
data:
  sentry-issues-events-overview_rev2.json: |-
    {
      "__inputs": [
        {
          "name": "DS_PROMETHEUS",
          "label": "Prometheus",
          "description": "",
          "type": "datasource",
          "pluginId": "prometheus",
          "pluginName": "Prometheus"
        }
      ],
      "__requires": [
        {
          "type": "grafana",
          "id": "grafana",
          "name": "Grafana",
          "version": "7.4.2"
        },
        {
          "type": "panel",
          "id": "graph",
          "name": "Graph",
          "version": ""
        },
        {
          "type": "panel",
          "id": "heatmap",
          "name": "Heatmap",
          "version": ""
        },
        {
          "type": "datasource",
          "id": "prometheus",
          "name": "Prometheus",
          "version": "1.0.0"
        },
        {
          "type": "panel",
          "id": "stat",
          "name": "Stat",
          "version": ""
        },
        {
          "type": "panel",
          "id": "table",
          "name": "Table",
          "version": ""
        }
      ],
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "gnetId": 13941,
      "graphTooltip": 0,
      "id": null,
      "iteration": 1614044172898,
      "links": [],
      "panels": [
        {
          "datasource": "${DS_PROMETHEUS}",
          "description": "Total number of new issues open in the past 1h",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {},
              "mappings": [],
              "noValue": "N/A",
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "#07b07d",
                    "value": null
                  },
                  {
                    "color": "#ffd757",
                    "value": 15
                  },
                  {
                    "color": "#d35755",
                    "value": 30
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 5,
            "w": 8,
            "x": 0,
            "y": 0
          },
          "id": 8,
          "options": {
            "colorMode": "background",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "reduceOptions": {
              "calcs": [
                "last"
              ],
              "fields": "",
              "values": false
            },
            "text": {},
            "textMode": "auto"
          },
          "pluginVersion": "7.4.2",
          "targets": [
            {
              "expr": "sum(sentry_open_issue_events{project_slug=~\"$project\", release=~\"$release\", environment=~\"$environment\"})",
              "instant": false,
              "interval": "10m",
              "legendFormat": "Issues",
              "refId": "A"
            }
          ],
          "title": "Total number of New Issues",
          "type": "stat"
        },
        {
          "datasource": "${DS_PROMETHEUS}",
          "description": "Total events per second in 30 minutes vector",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {},
              "decimals": 2,
              "mappings": [],
              "noValue": "N/A",
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "#07b07d",
                    "value": null
                  },
                  {
                    "color": "#ffd757",
                    "value": 10
                  },
                  {
                    "color": "#d35755",
                    "value": 20
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 5,
            "w": 8,
            "x": 8,
            "y": 0
          },
          "id": 6,
          "options": {
            "colorMode": "background",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "reduceOptions": {
              "calcs": [
                "last"
              ],
              "fields": "",
              "values": false
            },
            "text": {},
            "textMode": "auto"
          },
          "pluginVersion": "7.4.2",
          "targets": [
            {
              "expr": "sum(rate(sentry_events_total{project_slug=~\"$project\"}[30m]))",
              "instant": false,
              "interval": "10m",
              "legendFormat": "events",
              "refId": "A"
            }
          ],
          "title": "Total events (per sec)",
          "type": "stat"
        },
        {
          "datasource": "${DS_PROMETHEUS}",
          "description": "Total number of events in new issues in the past 24h range",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {},
              "mappings": [],
              "noValue": "N/A",
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "#07b07d",
                    "value": null
                  },
                  {
                    "color": "#ffd757",
                    "value": 20
                  },
                  {
                    "color": "#d35755",
                    "value": 30
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 5,
            "w": 8,
            "x": 16,
            "y": 0
          },
          "id": 9,
          "options": {
            "colorMode": "background",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "reduceOptions": {
              "calcs": [
                "last"
              ],
              "fields": "",
              "values": false
            },
            "text": {},
            "textMode": "auto"
          },
          "pluginVersion": "7.4.2",
          "targets": [
            {
              "expr": "sum(sentry_issues_bucket{project_slug=~\"$project\", environment=~\"$environment\",le=\"24h\"})",
              "instant": false,
              "interval": "10m",
              "legendFormat": "events",
              "refId": "A"
            }
          ],
          "title": "Total events in new issues (last 24h)",
          "type": "stat"
        },
        {
          "cards": {
            "cardPadding": null,
            "cardRound": 10
          },
          "color": {
            "cardColor": "#b4ff00",
            "colorScale": "sqrt",
            "colorScheme": "interpolateBuGn",
            "exponent": 0.5,
            "max": null,
            "min": null,
            "mode": "spectrum"
          },
          "dataFormat": "tsbuckets",
          "datasource": "${DS_PROMETHEUS}",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "gridPos": {
            "h": 8,
            "w": 13,
            "x": 0,
            "y": 5
          },
          "heatmap": {},
          "hideZeroBuckets": false,
          "highlightCards": true,
          "id": 11,
          "legend": {
            "show": true
          },
          "pluginVersion": "7.4.2",
          "reverseYBuckets": false,
          "targets": [
            {
              "expr": "sum(sentry_issues_bucket{project_slug=~\"$project\", environment=~\"$environment\", le=\"1h\"}) by (project_slug)",
              "format": "heatmap",
              "instant": false,
              "interval": "10m",
              "legendFormat": "{{ project_slug }}",
              "refId": "A"
            }
          ],
          "title": "New issues by project (last 1h)",
          "tooltip": {
            "show": true,
            "showHistogram": true
          },
          "transformations": [],
          "type": "heatmap",
          "xAxis": {
            "show": true
          },
          "xBucketNumber": null,
          "xBucketSize": null,
          "yAxis": {
            "decimals": null,
            "format": "short",
            "logBase": 1,
            "max": null,
            "min": null,
            "show": true,
            "splitFactor": null
          },
          "yBucketBound": "auto",
          "yBucketNumber": null,
          "yBucketSize": null
        },
        {
          "datasource": "${DS_PROMETHEUS}",
          "description": "Total number of new issues by project release",
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "custom": {
                "align": null,
                "displayMode": "auto",
                "filterable": false
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "#ffd757",
                    "value": 30
                  },
                  {
                    "color": "#ffa91f",
                    "value": 70
                  },
                  {
                    "color": "#d35755",
                    "value": 100
                  }
                ]
              }
            },
            "overrides": [
              {
                "matcher": {
                  "id": "byName",
                  "options": "Value (sum)"
                },
                "properties": [
                  {
                    "id": "displayName",
                    "value": "Issues"
                  }
                ]
              },
              {
                "matcher": {
                  "id": "byName",
                  "options": "Value (sum)"
                },
                "properties": [
                  {
                    "id": "custom.displayMode",
                    "value": "basic"
                  }
                ]
              }
            ]
          },
          "gridPos": {
            "h": 8,
            "w": 11,
            "x": 13,
            "y": 5
          },
          "id": 12,
          "options": {
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "Issues"
              }
            ]
          },
          "pluginVersion": "7.4.2",
          "targets": [
            {
              "exemplar": false,
              "expr": "sum(sentry_open_issue_events{project_slug=~\"$project\", release=~\"$release\", environment=~\"$environment\"}) by (project_slug, release, environment)",
              "format": "table",
              "instant": false,
              "interval": "10m",
              "legendFormat": "{{ project_slug }}: {{ release }}",
              "refId": "A"
            }
          ],
          "timeFrom": null,
          "timeShift": null,
          "title": "Events in new Issues by release",
          "transformations": [
            {
              "id": "groupBy",
              "options": {
                "fields": {
                  "Time": {
                    "aggregations": [],
                    "operation": null
                  },
                  "Value": {
                    "aggregations": [
                      "sum"
                    ],
                    "operation": "aggregate"
                  },
                  "environment": {
                    "aggregations": [],
                    "operation": "groupby"
                  },
                  "project_slug": {
                    "aggregations": [],
                    "operation": "groupby"
                  },
                  "release": {
                    "aggregations": [
                      "last"
                    ],
                    "operation": "groupby"
                  }
                }
              }
            },
            {
              "id": "organize",
              "options": {
                "excludeByName": {},
                "indexByName": {
                  "Value (sum)": 3,
                  "environment": 1,
                  "project_slug": 0,
                  "release": 2
                },
                "renameByName": {}
              }
            }
          ],
          "type": "table"
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "${DS_PROMETHEUS}",
          "fieldConfig": {
            "defaults": {
              "custom": {}
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 8,
            "x": 0,
            "y": 13
          },
          "hiddenSeries": false,
          "id": 2,
          "legend": {
            "alignAsTable": true,
            "avg": true,
            "current": true,
            "max": true,
            "min": true,
            "show": true,
            "sort": "total",
            "sortDesc": true,
            "total": true,
            "values": true
          },
          "lines": true,
          "linewidth": 1,
          "nullPointMode": "null as zero",
          "options": {
            "alertThreshold": true
          },
          "percentage": false,
          "pluginVersion": "7.4.2",
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(sentry_open_issue_events) by (project_slug)",
              "interval": "10m",
              "legendFormat": "{{ project_slug }}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "New Issues by project",
          "tooltip": {
            "shared": true,
            "sort": 2,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "$$hashKey": "object:571",
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "$$hashKey": "object:572",
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": true,
          "dashLength": 10,
          "dashes": false,
          "datasource": "${DS_PROMETHEUS}",
          "fieldConfig": {
            "defaults": {
              "color": {},
              "custom": {},
              "thresholds": {
                "mode": "absolute",
                "steps": []
              }
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 8,
            "x": 8,
            "y": 13
          },
          "hiddenSeries": false,
          "id": 13,
          "legend": {
            "alignAsTable": true,
            "avg": true,
            "current": true,
            "max": true,
            "min": true,
            "show": true,
            "total": true,
            "values": true
          },
          "lines": false,
          "linewidth": 1,
          "nullPointMode": "null as zero",
          "options": {
            "alertThreshold": true
          },
          "percentage": false,
          "pluginVersion": "7.4.2",
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": true,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(sentry_open_issue_events{project_slug=~\"$project\", release=~\"$release\", environment=~\"$environment\"}) by (environment)",
              "interval": "10m",
              "legendFormat": "{{ environment }}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "New Issues by environment",
          "tooltip": {
            "shared": true,
            "sort": 2,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "$$hashKey": "object:1248",
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "$$hashKey": "object:1249",
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "${DS_PROMETHEUS}",
          "decimals": 2,
          "fieldConfig": {
            "defaults": {
              "custom": {},
              "unit": "none"
            },
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 8,
            "x": 16,
            "y": 13
          },
          "hiddenSeries": false,
          "id": 4,
          "legend": {
            "alignAsTable": true,
            "avg": true,
            "current": true,
            "max": true,
            "min": true,
            "show": true,
            "sort": "current",
            "sortDesc": true,
            "total": false,
            "values": true
          },
          "lines": true,
          "linewidth": 1,
          "nullPointMode": "connected",
          "options": {
            "alertThreshold": true
          },
          "percentage": false,
          "pluginVersion": "7.4.2",
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "sum(rate(sentry_events_total[30m])) by (project_slug)",
              "interval": "10m",
              "legendFormat": "{{ project_slug }}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Events by project (per sec)",
          "tooltip": {
            "shared": true,
            "sort": 2,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "$$hashKey": "object:277",
              "decimals": 2,
              "format": "none",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "$$hashKey": "object:278",
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": false
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        }
      ],
      "refresh": "5m",
      "schemaVersion": 27,
      "style": "dark",
      "tags": [],
      "templating": {
        "list": [
          {
            "current": {
              "selected": false,
              "text": "Prometheus",
              "value": "Prometheus"
            },
            "hide": 2,
            "includeAll": false,
            "label": "Data Source",
            "multi": false,
            "name": "DS_PROMETHEUS",
            "options": [],
            "query": "prometheus",
            "refresh": 1,
            "regex": "",
            "skipUrlSync": false,
            "type": "datasource"
          },
          {
            "allValue": null,
            "current": {},
            "datasource": "${DS_PROMETHEUS}",
            "definition": "label_values(sentry_open_issue_events, project_slug)",
            "description": null,
            "error": null,
            "hide": 0,
            "includeAll": true,
            "label": "project",
            "multi": true,
            "name": "project",
            "options": [],
            "query": {
              "query": "label_values(sentry_open_issue_events, project_slug)",
              "refId": "StandardVariableQuery"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
          },
          {
            "allValue": null,
            "current": {},
            "datasource": "${DS_PROMETHEUS}",
            "definition": "label_values(sentry_open_issue_events{project_slug=~\"$project\"}, environment)",
            "description": null,
            "error": null,
            "hide": 0,
            "includeAll": true,
            "label": "environment",
            "multi": true,
            "name": "environment",
            "options": [],
            "query": {
              "query": "label_values(sentry_open_issue_events{project_slug=~\"$project\"}, environment)",
              "refId": "StandardVariableQuery"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
          },
          {
            "allValue": null,
            "current": {},
            "datasource": "${DS_PROMETHEUS}",
            "definition": "label_values(sentry_open_issue_events{project_slug=~\"$project\"}, release)",
            "description": null,
            "error": null,
            "hide": 0,
            "includeAll": true,
            "label": "release",
            "multi": true,
            "name": "release",
            "options": [],
            "query": {
              "query": "label_values(sentry_open_issue_events{project_slug=~\"$project\"}, release)",
              "refId": "StandardVariableQuery"
            },
            "refresh": 2,
            "regex": "",
            "skipUrlSync": false,
            "sort": 0,
            "tagValuesQuery": "",
            "tags": [],
            "tagsQuery": "",
            "type": "query",
            "useTags": false
          }
        ]
      },
      "time": {
        "from": "now-24h",
        "to": "now"
      },
      "timepicker": {
        "refresh_intervals": [
          "5s",
          "10s",
          "30s",
          "1m",
          "5m",
          "15m",
          "30m",
          "1h",
          "2h",
          "1d"
        ]
      },
      "timezone": "",
      "title": "Sentry Issues & Events Overview",
      "uid": "EPreUnsGz",
      "version": 9
    }
---
# Source: sentry/charts/sentry/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: release-name-sentry-data
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "10Gi"
---
# Source: sentry/charts/postgres/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sentry-master
  labels:
    spilo-role: master
    
    helm.sh/chart: postgres-0.2.1
    app.kubernetes.io/name: postgres
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9187"
spec:
  type: ClusterIP
  ports:
  - name: postgres
    port: 5432
    targetPort: 5432
  - name: http-metrics
    port: 9187
    targetPort: http-metrics
  selector:
    spilo-role: master
---
# Source: sentry/charts/postgres/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sentry-replica
  labels:
    spilo-role: replica
    
    helm.sh/chart: postgres-0.2.1
    app.kubernetes.io/name: postgres
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9187"
spec:
  type: ClusterIP
  ports:
  - name: postgres
    port: 5432
    targetPort: 5432
  - name: http-metrics
    port: 9187
    targetPort: http-metrics
  selector:
    spilo-role: replica
---
# Source: sentry/charts/sentry/templates/service-metrics.yaml
apiVersion: v1
kind: Service
metadata:
 name: release-name-sentry-metrics
 labels:
    app: release-name-sentry-metrics
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    role: metrics
spec:
  type: ClusterIP
  ports:
  - port: 9102
    targetPort: 9102
    protocol: TCP
    name: metrics
  - port: 9125
    targetPort: 9125
    protocol: UDP
    name: statsd
  selector:
    app: release-name-sentry-metrics
    release: release-name
    role: metrics
---
# Source: sentry/charts/sentry/templates/service-relay.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-sentry-relay
  annotations:
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
spec:
  type: ClusterIP
  ports:
  - port: 3000
    targetPort: 3000
    protocol: TCP
    name: sentry-relay
  selector:
    app: release-name-sentry
    role: relay
---
# Source: sentry/charts/sentry/templates/service-sentry.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-sentry-web
  annotations:
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
spec:
  type: ClusterIP
  ports:
  - port: 9000
    targetPort: 9000
    protocol: TCP
    name: sentry
  selector:
    app: release-name-sentry
    role: web
---
# Source: sentry/charts/sentry/templates/service-snuba.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-sentry-snuba
  annotations:
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
spec:
  type: ClusterIP
  ports:
  - port: 1218
    targetPort: 1218
    protocol: TCP
    name: sentry
  selector:
    app: release-name-sentry
    role: snuba-api
---
# Source: sentry/charts/sentry/templates/deployment-metrics.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-metrics
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
spec:
  selector:
    matchLabels:
      app: release-name-sentry-metrics
      release: "release-name"
      role: metrics
  replicas: 1
  revisionHistoryLimit: 10
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: release-name-sentry-metrics
        release: "release-name"
        role: metrics
    spec:
      containers:
      - name: sentry-metrics
        args:
          - "--statsd.listen-udp=:9125"
          - "--web.listen-address=:9102"
        image: "gcr.io/pluralsh/prom/statsd-exporter:v0.23.1"
        imagePullPolicy: IfNotPresent
        ports:
        - name: statsd
          containerPort: 9125
        - name: metrics
          containerPort: 9102
        livenessProbe:
          httpGet:
            path: /metrics
            port: 9102
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 2
          successThreshold: 1
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /metrics
            port: 9102
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 2
          successThreshold: 1
          failureThreshold: 3
        resources:
          {}
      serviceAccountName: sentry-metrics
---
# Source: sentry/charts/sentry/templates/deployment-relay.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-relay
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  selector:
    matchLabels:
      app: release-name-sentry
      release: "release-name"
      role: relay
  replicas: 1
  revisionHistoryLimit: 10
  template:
    metadata:
      annotations:
        checksum/relay: 8074a66c015a8309dc9bdef7524b89bb223749847663f454012dba4e7ed06cc3
        checksum/config.yaml: c1bde4ddb2914764e0b7750132d9b642e55e81ed0dd11bb42b153c4c2316a5ea
      labels:
        app: release-name-sentry
        release: "release-name"
        role: relay
    spec:
      affinity:
      initContainers:
        - name: sentry-relay-init
          image: "dkr.plural.sh/sentry/getsentry/relay:23.5.0"
          imagePullPolicy: IfNotPresent
          args:
            - "credentials"
            - "generate"
          resources:
            {}
          env:
            - name: RELAY_PORT
              value: '3000'
          volumeMounts:
            - name: credentials
              mountPath: /work/.relay
            - name: config
              mountPath: /work/.relay/config.yml
              subPath: config.yml
              readOnly: true
      containers:
      - name: sentry-relay
        image: "dkr.plural.sh/sentry/getsentry/relay:23.5.0"
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 3000
        env:
        - name: RELAY_PORT
          value: '3000'
        volumeMounts:
          - name: credentials
            mountPath: /work/.relay
          - name: config
            mountPath: /work/.relay/config.yml
            subPath: config.yml
            readOnly: true
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /api/relay/healthcheck/live/
            port: 3000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 2
        readinessProbe:
          failureThreshold: 5
          httpGet:
            path: /api/relay/healthcheck/ready/
            port: 3000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 2
        resources:
            {}
      serviceAccountName: sentry-relay
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-relay
          defaultMode: 0644
      - name: credentials
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-sentry-billing-metrics-consumer.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-billing-metrics-consumer
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: release-name-sentry
      release: "release-name"
      role: billing-metrics-consumer
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: release-name-sentry
        release: "release-name"
        role: billing-metrics-consumer
    spec:
      affinity:
      containers:
      - name: sentry-billing-metrics-consumer
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry"]
        args:
          - "run"
          - "billing-metrics-consumer"
        env:
        - name: C_FORCE_ROOT
          value: "true"
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        resources:
            {}
      serviceAccountName: sentry-billing-metrics-consumer
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-sentry-cron.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-cron
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: cron
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: release-name-sentry
        release: "release-name"
        role: cron
    spec:
      affinity:
      containers:
      - name: sentry-cron
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry"]
        args:
          - "run"
          - "cron"
        env:
        - name: C_FORCE_ROOT
          value: "true"
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        resources:
            {}
      serviceAccountName: sentry-cron
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-sentry-ingest-consumer.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-ingest-consumer
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: release-name-sentry
      release: "release-name"
      role: ingest-consumer
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: release-name-sentry
        release: "release-name"
        role: ingest-consumer
    spec:
      affinity:
      containers:
      - name: sentry-ingest-consumer
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry"]
        args:
          - "run"
          - "ingest-consumer"
          - "--all-consumer-types"
        env:
        - name: C_FORCE_ROOT
          value: "true"
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        resources:
            requests:
              cpu: 50m
              memory: 300Mi
      serviceAccountName: sentry-ingest-consumer
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-sentry-ingest-metrics-consumer-perf.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-ingest-metrics-consumer-perf
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: release-name-sentry
      release: "release-name"
      role: ingest-metrics-consumer-perf
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: release-name-sentry
        release: "release-name"
        role: ingest-metrics-consumer-perf
    spec:
      affinity:
      containers:
      - name: sentry-ingest-metrics-consumer-perf
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry"]
        args:
          - "run"
          - "ingest-metrics-parallel-consumer"
          - "--ingest-profile"
          - "performance"
        env:
        - name: C_FORCE_ROOT
          value: "true"
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        resources:
            {}
      serviceAccountName: sentry-ingest-metrics-consumer-perf
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-sentry-ingest-metrics-consumer-rh.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-ingest-metrics-consumer-rh
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: release-name-sentry
      release: "release-name"
      role: ingest-metrics-consumer-rh
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: release-name-sentry
        release: "release-name"
        role: ingest-metrics-consumer-rh
    spec:
      affinity:
      containers:
      - name: sentry-ingest-metrics-consumer-rh
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry"]
        args:
          - "run"
          - "ingest-metrics-parallel-consumer"
          - "--ingest-profile"
          - "release-health"
        env:
        - name: C_FORCE_ROOT
          value: "true"
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        resources:
            {}
      serviceAccountName: sentry-ingest-metrics-consumer-rh
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-sentry-ingest-replay-recordings.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-ingest-replay-recordings
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: release-name-sentry
      release: "release-name"
      role: ingest-replay-recordings
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: release-name-sentry
        release: "release-name"
        role: ingest-replay-recordings
    spec:
      affinity:
      containers:
      - name: sentry-ingest-replay-recordings
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry"]
        args:
          - "run"
          - "ingest-replay-recordings"
        env:
        - name: C_FORCE_ROOT
          value: "true"
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        resources:
            {}
      serviceAccountName: sentry-ingest-replay-recordings
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-sentry-post-process-forwarder-errors.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-post-process-forward-errors
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: sentry
        release: "release-name"
        role: sentry-post-process-forward-errors
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: sentry
        release: "release-name"
        role: sentry-post-process-forward-errors
    spec:
      affinity:
      containers:
      - name: sentry-post-process-forward-errors
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry"]
        args:
          - "run"
          - "post-process-forwarder"
          - "--entity"
          - "errors"
        env:
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        resources:
            {}
      serviceAccountName: sentry-post-process-forwarder-errors
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-sentry-post-process-forwarder-transactions.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-post-process-forward-transactions
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: sentry
        release: "release-name"
        role: sentry-post-process-forward-transactions
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: sentry
        release: "release-name"
        role: sentry-post-process-forward-transactions
    spec:
      affinity:
      containers:
      - name: sentry-post-process-forward-transactions
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry"]
        args:
          - "run"
          - "post-process-forwarder"
          - "--entity"
          - "transactions"
          - "--commit-log-topic=snuba-transactions-commit-log"
          - "--synchronize-commit-group"
          - "transactions_group"
        env:
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        resources:
            {}
      serviceAccountName: sentry-post-process-forwarder-transactions
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-sentry-subscription-consumer-events.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-subscription-consumer-events
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: sentry
        release: "release-name"
        role: sentry-subscription-consumer-events
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: sentry
        release: "release-name"
        role: sentry-subscription-consumer-events
    spec:
      affinity:
      containers:
      - name: sentry-subscription-consumer-events
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry"]
        args:
          - "run"
          - "query-subscription-consumer"
          - "--topic"
          - "events-subscription-results"
        env:
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        resources:
            {}
      serviceAccountName: sentry-subscription-consumer-events
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-sentry-subscription-consumer-transactions.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-subscription-consumer-transactions
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: sentry
        release: "release-name"
        role: sentry-subscription-consumer-transactions
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: sentry
        release: "release-name"
        role: sentry-subscription-consumer-transactions
    spec:
      affinity:
      containers:
      - name: sentry-subscription-consumer-transactions
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry"]
        args:
          - "run"
          - "query-subscription-consumer"
          - "--topic"
          - "transactions-subscription-results"
        env:
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        resources:
            {}
      serviceAccountName: sentry-subscription-consumer-transactions
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-sentry-web.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-web
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
spec:
  revisionHistoryLimit: 10
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: web
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: release-name-sentry
        release: "release-name"
        role: web
    spec:
      affinity:
      containers:
      - name: sentry-web
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry", "run", "web"]
        ports:
        - containerPort: 9000
        env:
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /_health/
            port: 9000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 2
        readinessProbe:
          failureThreshold: 5
          httpGet:
            path: /_health/
            port: 9000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 2
        resources:
            requests:
              cpu: 50m
              memory: 350Mi
      serviceAccountName: sentry-web
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        persistentVolumeClaim:
          claimName: release-name-sentry-data
---
# Source: sentry/charts/sentry/templates/deployment-sentry-worker.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-worker
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: worker
  template:
    metadata:
      annotations:
        checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: release-name-sentry
        release: "release-name"
        role: worker
    spec:
      affinity:
      containers:
      - name: sentry-worker
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry"]
        args:
          - "run"
          - "worker"
        env:
        - name: C_FORCE_ROOT
          value: "true"
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        - mountPath: /var/lib/sentry/files
          name: sentry-data
        resources:
            requests:
              cpu: 50m
              memory: 750Mi
      serviceAccountName: sentry-worker
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
      - name: sentry-data
        emptyDir: {}
---
# Source: sentry/charts/sentry/templates/deployment-snuba-api.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-snuba-api
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: release-name-sentry
      release: "release-name"
      role: snuba-api
  template:
    metadata:
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-api
    spec:
      affinity:
      containers:
      - name: sentry-snuba
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 1218
        env:
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /
            port: 1218
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 2
        readinessProbe:
          failureThreshold: 10
          httpGet:
            path: /
            port: 1218
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 2
        resources:
            requests:
              cpu: 20m
              memory: 100Mi
      serviceAccountName: sentry-snuba
      volumes:
        - name: config
          configMap:
            name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/deployment-snuba-consumer.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-snuba-consumer
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-consumer
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-consumer
    spec:
      affinity:
      containers:
      - name: sentry-snuba
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        imagePullPolicy: IfNotPresent
        command:
          - "snuba"
          - "consumer"
          - "--storage"
          - "errors"
          - "--auto-offset-reset"
          - "earliest"
          - "--max-batch-time-ms"
          - "750"
        ports:
        - containerPort: 1218
        env:
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        resources:
            requests:
              cpu: 20m
              memory: 100Mi
      serviceAccountName: sentry-snuba
      volumes:
        - name: config
          configMap:
            name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/deployment-snuba-outcomes-consumer.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-snuba-outcomes-consumer
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-outcomes-consumer
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-outcomes-consumer
    spec:
      affinity:
      containers:
      - name: sentry-snuba
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        imagePullPolicy: IfNotPresent
        command:
          - "snuba"
          - "consumer"
          - "--storage"
          - "outcomes_raw"
          - "--auto-offset-reset"
          - "earliest"
          - "--max-batch-size"
          - "3"
        ports:
        - containerPort: 1218
        env:
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        resources:
            requests:
              cpu: 20m
              memory: 100Mi
      serviceAccountName: sentry-snuba
      volumes:
        - name: config
          configMap:
            name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/deployment-snuba-replacer.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-snuba-replacer
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-replacer
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-replacer
    spec:
      affinity:
      containers:
      - name: sentry-snuba
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        imagePullPolicy: IfNotPresent
        command:
          - "snuba"
          - "replacer"
          - "--storage"
          - "errors"
          - "--auto-offset-reset"
          - "earliest"
        ports:
        - containerPort: 1218
        env:
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        resources:
            requests:
              cpu: 20m
              memory: 100Mi
      serviceAccountName: sentry-snuba
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/deployment-snuba-replays-consumer.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-snuba-replays-consumer
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-replays-consumer
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-replays-consumer
    spec:
      affinity:
      containers:
      - name: sentry-snuba
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        imagePullPolicy: IfNotPresent
        command:
          - "snuba"
          - "consumer"
          - "--storage"
          - "replays"
          - "--consumer-group"
          - "replays_group"
          - "--auto-offset-reset"
          - "earliest"
          - "--max-batch-time-ms"
          - "750"
        ports:
        - containerPort: 1218
        env:
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        resources:
            {}
      serviceAccountName: sentry-snuba
      volumes:
        - name: config
          configMap:
            name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/deployment-snuba-sessions-consumer.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-sessions-consumer
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: sessions-consumer
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: release-name-sentry
        release: "release-name"
        role: sessions-consumer
    spec:
      affinity:
      containers:
      - name: sentry-snuba
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        imagePullPolicy: IfNotPresent
        command:
          - "snuba"
          - "consumer"
          - "--storage"
          - "sessions_raw"
          - "--auto-offset-reset"
          - "earliest"
          - "--max-batch-time-ms"
          - "750"
        ports:
        - containerPort: 1218
        env:
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        resources:
            requests:
              cpu: 20m
              memory: 100Mi
      serviceAccountName: sentry-snuba
      volumes:
        - name: config
          configMap:
            name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/deployment-snuba-subscription-consumer-events.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-snuba-subscription-consumer-events
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-subscription-consumer-events
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-subscription-consumer-events
    spec:
      affinity:
      containers:
      - name: sentry-snuba
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        imagePullPolicy: IfNotPresent
        command:
          - "snuba"
          - "subscriptions-scheduler-executor"
          - "--auto-offset-reset=earliest"
          - "--dataset=events"
          - "--entity=events"
          - "--consumer-group=snuba-events-subscriptions-consumers"
          - "--followed-consumer-group=snuba-consumers"
          - "--delay-seconds=60"
          - "--schedule-ttl=60"
          - "--stale-threshold-seconds=900"
        ports:
        - containerPort: 1218
        env:
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        resources:
            {}
      serviceAccountName: sentry-snuba
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/deployment-snuba-subscription-consumer-sessions.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-snuba-subscription-consumer-sessions
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-subscription-consumer-sessions
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-subscription-consumer-sessions
    spec:
      affinity:
      containers:
      - name: sentry-snuba
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        imagePullPolicy: IfNotPresent
        command:
          - "snuba"
          - "subscriptions-scheduler-executor"
          - "--auto-offset-reset=earliest"
          - "--dataset=sessions"
          - "--entity=sessions"
          - "--consumer-group=snuba-sessions-subscriptions-consumers"
          - "--followed-consumer-group=snuba-consumers"
          - "--delay-seconds=60"
          - "--schedule-ttl=60"
          - "--stale-threshold-seconds=900"
        ports:
        - containerPort: 1218
        env:
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        resources:
            {}
      serviceAccountName: sentry-snuba
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/deployment-snuba-subscription-consumer-transactions.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-snuba-subscription-consumer-transactions
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-subscription-consumer-transactions
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-subscription-consumer-transactions
    spec:
      affinity:
      containers:
      - name: sentry-snuba
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        imagePullPolicy: IfNotPresent
        command:
          - "snuba"
          - "subscriptions-scheduler-executor"
          - "--auto-offset-reset=earliest"
          - "--dataset=transactions"
          - "--entity=transactions"
          - "--consumer-group=snuba-transactions-subscriptions-consumers"
          - "--followed-consumer-group=transactions_group"
          - "--delay-seconds=60"
          - "--schedule-ttl=60"
          - "--stale-threshold-seconds=900"
        ports:
        - containerPort: 1218
        env:
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        resources:
            {}
      serviceAccountName: sentry-snuba
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/deployment-snuba-transactions-consumer.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-sentry-snuba-transactions-consumer
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-transactions-consumer
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: release-name-sentry
        release: "release-name"
        role: snuba-transactions-consumer
    spec:
      affinity:
      containers:
      - name: sentry-snuba
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        imagePullPolicy: IfNotPresent
        command:
          - "snuba"
          - "consumer"
          - "--storage"
          - "transactions"
          - "--consumer-group"
          - "transactions_group"
          - "--auto-offset-reset"
          - "earliest"
          - "--max-batch-time-ms"
          - "750"
        ports:
        - containerPort: 1218
        env:
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        resources:
            requests:
              cpu: 20m
              memory: 100Mi
      serviceAccountName: sentry-snuba
      volumes:
        - name: config
          configMap:
            name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/hpa-ingestConsumer.yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: release-name-sentry-sentry-ingest-consumer
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: release-name-sentry-ingest-consumer
  minReplicas: 1
  maxReplicas: 3
  targetCPUUtilizationPercentage: 50
---
# Source: sentry/charts/sentry/templates/hpa-snuba-api.yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: release-name-sentry-snuba-api
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: release-name-sentry-snuba-api
  minReplicas: 2
  maxReplicas: 5
  targetCPUUtilizationPercentage: 50
---
# Source: sentry/charts/sentry/templates/hpa-web.yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: release-name-sentry-sentry-web
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: release-name-sentry-web
  minReplicas: 2
  maxReplicas: 5
  targetCPUUtilizationPercentage: 50
---
# Source: sentry/charts/sentry/templates/hpa-worker.yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: release-name-sentry-sentry-worker
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: release-name-sentry-worker
  minReplicas: 2
  maxReplicas: 5
  targetCPUUtilizationPercentage: 50
---
# Source: sentry/charts/sentry/templates/cronjob-sentry-cleanup.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: release-name-sentry-sentry-cleanup
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
spec:
  schedule: "0 0 * * *"
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 5
  concurrencyPolicy: "Allow"
  jobTemplate:
    spec:
      activeDeadlineSeconds: 100
      template:
        metadata:
          annotations:
            checksum/configYml: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
            checksum/sentryConfPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
            checksum/config.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
          labels:
            app: release-name-sentry
            release: "release-name"
        spec:
          affinity:
          containers:
          - name: sentry-sentry-cleanup
            image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
            imagePullPolicy: IfNotPresent
            command: ["sentry"]
            args:
              - "cleanup"
              - "--concurrency"
              - "1"
              - "--days"
              - "90"
            env:
            - name: C_FORCE_ROOT
              value: "true"
            - name: SNUBA
              value: http://release-name-sentry-snuba:1218
            - name: SENTRY_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: sentry-system-secret
                  key: key
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
                  key: password
            volumeMounts:
            - mountPath: /etc/sentry
              name: config
              readOnly: true
            - mountPath: /var/lib/sentry/files
              name: sentry-data
            resources:
              null
          restartPolicy: Never
          volumes:
          - name: config
            configMap:
              name: release-name-sentry-sentry
          - name: sentry-data
            emptyDir: {}
---
# Source: sentry/charts/sentry/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
 name: release-name-sentry
 labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
 annotations:
     cert-manager.io/cluster-issuer: "letsencrypt-prod"
     kubernetes.io/tls-acme: "true"
     nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
     nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  ingressClassName: "nginx"
  rules:
    - host: 
      http:
        paths:
          - path: /api/store
            pathType: ImplementationSpecific
            backend:
              service:
                name: release-name-sentry-relay
                port:
                  number: 3000
          - path: /api/[1-9][0-9]*/(.*)
            pathType: ImplementationSpecific
            backend:
              service:
                name: release-name-sentry-relay
                port:
                  number: 3000
          - path: "/"
            pathType: ImplementationSpecific
            backend:
              service:
                name: release-name-sentry-web
                port:
                  number: 9000
---
# Source: sentry/charts/clickhouse/templates/clickhouse_instance.yaml
apiVersion: "clickhouse.altinity.com/v1"
kind: "ClickHouseInstallation"
metadata:
  name: release-name-clickhouse
spec:
  defaults:
    templates:
      serviceTemplate: service-template
      replicaServiceTemplate: replica-service-template
  configuration:
    users:
      admin/password: change_me
      admin/networks/ip:
        - "10.0.0.0/8"
        - "172.16.0.0/12"
        - "192.168.0.0/16"
      admin/profile: default
      admin/quota: default
    profiles:
      default/allow_experimental_window_functions: "1"
      default/allow_nondeterministic_mutations: "1"

    clusters:
      - name: "sentry"
        templates:
          podTemplate: pod-template
          clusterServiceTemplate: cluster-service-template
          dataVolumeClaimTemplate: data-volumeclaim-template
        layout:
          shardsCount: 1
          replicasCount: 3
          shards:
            - files:
                keeper_config.xml: |
                  <clickhouse>
                      <include_from>/tmp/clickhouse-keeper/config.d/generated-keeper-settings.xml</include_from>
                      <keeper_server incl="keeper_server">
                          <path>/var/lib/clickhouse-keeper</path>
                          <tcp_port>9181</tcp_port>
                          <four_letter_word_white_list>*</four_letter_word_white_list>
                          <coordination_settings>
                              <!-- <raft_logs_level>trace</raft_logs_level> -->
                              <raft_logs_level>information</raft_logs_level>
                          </coordination_settings>
                      </keeper_server>
                  </clickhouse>
              replicas:
                - templates:
                    podTemplate: pod-template-clickhouse-keeper
                    replicaServiceTemplate: replica-service-template-clickhouse-keeper
                - templates:
                    podTemplate: pod-template-clickhouse-keeper
                    replicaServiceTemplate: replica-service-template-clickhouse-keeper
                - templates:
                    podTemplate: pod-template-clickhouse-keeper
                    replicaServiceTemplate: replica-service-template-clickhouse-keeper

    settings:
      default_database: sentry
      format_schema_path: /etc/clickhouse-server/config.d/

    zookeeper:
      nodes:
        - host: service-release-name-clickhouse-0-0.default.svc.cluster.local
          port: 9181
        - host: service-release-name-clickhouse-0-1.default.svc.cluster.local
          port: 9181
        - host: service-release-name-clickhouse-0-2.default.svc.cluster.local
          port: 9181

  templates:
    podTemplates:
      - name: pod-template
        podDistribution: 
            - scope: Shard
              topologyKey: kubernetes.io/hostname
              type: ShardAntiAffinity
        spec:
          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: topology.kubernetes.io/zone
              whenUnsatisfiable: DoNotSchedule
              labelSelector:
                matchExpressions:
                - key: clickhouse.altinity.com/chi
                  operator: In
                  values:
                  - release-name-clickhouse
          securityContext:
            fsGroup: 101
            runAsGroup: 101
            runAsUser: 101
          serviceAccountName: release-name-clickhouse

          containers:
            - name: clickhouse
              image: "dkr.plural.sh/clickhouse/clickhouse/clickhouse-server:22.8.11.15"
              env:
              command:
                - /bin/bash
                - -c
                - /usr/bin/clickhouse-server --config-file=/etc/clickhouse-server/config.xml
              ports:
                - name: http
                  containerPort: 8123
                - name: client
                  containerPort: 9000
                - name: interserver
                  containerPort: 9009
              volumeMounts:
                - name: data-volumeclaim-template
                  mountPath: /var/lib/clickhouse
              resources: 
                limits:
                  cpu: 500m
                  memory: 1Gi
                requests:
                  cpu: 150m
                  memory: 300Mi
      - name: pod-template-clickhouse-keeper
        podDistribution: 
            - scope: Shard
              topologyKey: kubernetes.io/hostname
              type: ShardAntiAffinity
        spec:
          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: topology.kubernetes.io/zone
              whenUnsatisfiable: DoNotSchedule
              labelSelector:
                matchExpressions:
                - key: clickhouse.altinity.com/chi
                  operator: In
                  values:
                  - release-name-clickhouse
          serviceAccountName: release-name-clickhouse
          securityContext:
            fsGroup: 101
            runAsGroup: 101
            runAsUser: 101

          containers:
            - name: clickhouse
              image: "dkr.plural.sh/clickhouse/clickhouse/clickhouse-server:22.8.11.15"
              env:
              - name: KEEPER_SERVERS
                value: "3"
              - name: RAFT_PORT
                value: "9444"
              command:
                - /bin/bash
                - -c
                - |
                  HOST=`hostname -s` &&
                  DOMAIN=`hostname -d` &&
                  if [[ $HOST =~ (.*)-([0-9]+)-([0-9]+)$ ]]; then
                      NAME=${BASH_REMATCH[1]}
                      ORD=${BASH_REMATCH[2]}
                      SUFFIX=${BASH_REMATCH[3]}
                  else
                      echo "Failed to parse name and ordinal of Pod"
                      exit 1
                  fi &&
                  if [[ $DOMAIN =~ (.*)-([0-9]+)(.default.svc.cluster.local)$ ]]; then
                      DOMAIN_NAME=${BASH_REMATCH[1]}
                      DOMAIN_ORD=${BASH_REMATCH[2]}
                      DOMAIN_SUFFIX=${BASH_REMATCH[3]}
                  else
                      echo "Failed to parse name and ordinal of Pod"
                      exit 1
                  fi &&
                  export MY_ID=$((ORD+1)) &&
                  mkdir -p /tmp/clickhouse-keeper/config.d/ &&
                  {
                    echo "<yandex><keeper_server>"
                    echo "<server_id>${MY_ID}</server_id>"
                    echo "<raft_configuration>"
                    for (( i=1; i<=$KEEPER_SERVERS; i++ )); do
                        echo "<server><id>${i}</id><hostname>$NAME-$((i-1))-${SUFFIX}.${DOMAIN_NAME}-$((i-1))${DOMAIN_SUFFIX}</hostname><port>${RAFT_PORT}</port></server>"
                    done
                    echo "</raft_configuration>"
                    echo "</keeper_server></yandex>"
                  } > /tmp/clickhouse-keeper/config.d/generated-keeper-settings.xml &&
                  cat /tmp/clickhouse-keeper/config.d/generated-keeper-settings.xml &&
                  /usr/bin/clickhouse-server --config-file=/etc/clickhouse-server/config.xml

              ports:
                - name: http
                  containerPort: 8123
                - name: client
                  containerPort: 9000
                - name: interserver
                  containerPort: 9009
                - name: raft
                  containerPort: 9444
                - name: ch-keeper
                  containerPort: 9181
              volumeMounts:
                - name: data-volumeclaim-template
                  mountPath: /var/lib/clickhouse
              # configures probes for clickhouse keeper
              # without this, traffic is not sent through the service and clickhouse keeper cannot start
              readinessProbe:
                tcpSocket:
                  port: 9444
                initialDelaySeconds: 10
                timeoutSeconds: 5
                periodSeconds: 10
                failureThreshold: 3
              livenessProbe:
                tcpSocket:
                  port: 9181
                initialDelaySeconds: 30
                timeoutSeconds: 5
                periodSeconds: 10
              resources: 
                limits:
                  cpu: 500m
                  memory: 1Gi
                requests:
                  cpu: 150m
                  memory: 300Mi
    serviceTemplates:
      - name: service-template
        generateName: service-{chi}
        spec:
          ports:
            - name: http
              port: 8123
            - name: tcp
              port: 9000
            - name: clickhouse-keeper
              port: 9181
          type: ClusterIP
      - name: cluster-service-template
        generateName: service-{chi}-{cluster}
        spec:
          ports:
            - name: http
              port: 8123
            - name: tcp
              port: 9000
          type: ClusterIP
          clusterIP: None
      - name: replica-service-template
        generateName: service-{chi}-{shard}-{replica}
        spec:
          ports:
            - name: http
              port: 8123
            - name: tcp
              port: 9000
            - name: interserver
              port: 9009
          type: ClusterIP
      - name: replica-service-template-clickhouse-keeper
        generateName: service-{chi}-{shard}-{replica}
        spec:
          ports:
            - name: http
              port: 8123
            - name: tcp
              port: 9000
            - name: interserver
              port: 9009
            - name: clickhouse-keeper
              port: 9181
            - name: raft
              port: 9444
          type: ClusterIP
    volumeClaimTemplates:
      - name: data-volumeclaim-template
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: "20Gi"
---
# Source: sentry/templates/configuration_overlays.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: ConfigurationOverlay
metadata:
  name: web-cpu
  labels:
    helm.sh/chart: sentry-0.2.16
    app.kubernetes.io/name: sentry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "23.5.0"
    app.kubernetes.io/managed-by: Helm

  
    platform.plural.sh/component: sentry-web
    platform.plural.sh/kind: deployment
    platform.plural.sh/resource: cpu

spec:

  documentation: cpu requests for web deployment
  name: web cpu
  updates:
  - path:
    - sentry
    - sentry
    - sentry
    - web
    - resources
    - requests
    - cpu
---
# Source: sentry/templates/configuration_overlays.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: ConfigurationOverlay
metadata:
  name: web-mem
  labels:
    helm.sh/chart: sentry-0.2.16
    app.kubernetes.io/name: sentry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "23.5.0"
    app.kubernetes.io/managed-by: Helm

  
    platform.plural.sh/component: sentry-web
    platform.plural.sh/kind: deployment
    platform.plural.sh/resource: memory

spec:

  documentation: memory requests for web deployment
  name: web memory
  updates:
  - path:
    - sentry
    - sentry
    - sentry
    - web
    - resources
    - requests
    - memory
---
# Source: sentry/templates/configuration_overlays.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: ConfigurationOverlay
metadata:
  name: worker-cpu
  labels:
    helm.sh/chart: sentry-0.2.16
    app.kubernetes.io/name: sentry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "23.5.0"
    app.kubernetes.io/managed-by: Helm

  
    platform.plural.sh/component: sentry-worker
    platform.plural.sh/kind: deployment
    platform.plural.sh/resource: cpu

spec:

  documentation: cpu requests for worker deployment
  name: worker cpu
  updates:
  - path:
    - sentry
    - sentry
    - sentry
    - worker
    - resources
    - requests
    - cpu
---
# Source: sentry/templates/configuration_overlays.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: ConfigurationOverlay
metadata:
  name: worker-mem
  labels:
    helm.sh/chart: sentry-0.2.16
    app.kubernetes.io/name: sentry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "23.5.0"
    app.kubernetes.io/managed-by: Helm

  
    platform.plural.sh/component: sentry-worker
    platform.plural.sh/kind: deployment
    platform.plural.sh/resource: memory

spec:

  documentation: memory requests for worker deployment
  name: worker memory
  updates:
  - path:
    - sentry
    - sentry
    - sentry
    - worker
    - resources
    - requests
    - memory
---
# Source: sentry/templates/configuration_overlays.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: ConfigurationOverlay
metadata:
  name: clickhouse-cpu
  labels:
    helm.sh/chart: sentry-0.2.16
    app.kubernetes.io/name: sentry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "23.5.0"
    app.kubernetes.io/managed-by: Helm

  
    platform.plural.sh/component: sentry-clickhouse
    platform.plural.sh/kind: statefulset
    platform.plural.sh/resource: cpu

spec:

  documentation: cpu requests for clickhouse statefulset
  name: clickhouse cpu
  updates:
  - path:
    - sentry
    - sentry
    - clickhouse
    - clickhouse
    - resources
    - requests
    - cpu
---
# Source: sentry/templates/configuration_overlays.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: ConfigurationOverlay
metadata:
  name: clickhouse-mem
  labels:
    helm.sh/chart: sentry-0.2.16
    app.kubernetes.io/name: sentry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "23.5.0"
    app.kubernetes.io/managed-by: Helm

  
    platform.plural.sh/component: sentry-clickhouse
    platform.plural.sh/kind: statefulset
    platform.plural.sh/resource: memory

spec:

  documentation: memory requests for clickhouse statefulset
  name: clickhouse memory
  updates:
  - path:
    - sentry
    - sentry
    - clickhouse
    - clickhouse
    - resources
    - requests
    - memory
---
# Source: sentry/charts/postgres/templates/dashboard.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: Dashboard
metadata:
  name: sentry-postgres
  labels:
    helm.sh/chart: postgres-0.2.1
    app.kubernetes.io/name: postgres
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  name: postgres
  description: Monitoring for your sentry postgres db
  timeslices: [30m, 1h, 2h, 1d]
  defaultTime: 30m
  labels:
  - name: instance
    query:
      query: pg_stat_database_tup_fetched{namespace="default"}
      label: instance
  graphs:
  - queries:
    - query: SUM(pg_stat_database_tup_fetched{instance=~"$instance"})
      legend: tuples fetched
    - query: SUM(pg_stat_database_tup_inserted{instance=~"$instance"})
      legend: tuples inserted
    - query: SUM(pg_stat_database_tup_updated{instance=~"$instance"})
      legend: tuples updated
    name: Storage Performance
  - queries:
    - query: pg_settings_max_connections{instance="$instance"}
      legend: connections
    name: Max Connections
  - queries:
    - query: avg(rate(process_cpu_seconds_total{instance="$instance"}[5m]) * 1000)
      legend: seconds
    name: CPU time
  - queries:
    - query: avg(rate(process_resident_memory_bytes{instance="$instance"}[5m]))
      legend: resident mem
    - query: avg(rate(process_virtual_memory_bytes{instance="$instance"}[5m]))
      legend: process mem
    format: bytes
    name: Memory utilization
  - queries:
    - query: process_open_fds{instance="$instance"}
      legend: fds
    name: Open file descriptors
  - queries:
    - query: pg_settings_max_wal_size_bytes{instance="$instance"}
      legend: WAL size
    name: Max WAL size
  - queries:
    - query: irate(pg_stat_database_xact_commit{instance="$instance"}[5m])
      legend: commits
    - query: irate(pg_stat_database_xact_rollback{instance="$instance"}[5m])
      legend: rollbacks
    name: Transactions
  - queries:
    - query: pg_stat_database_blks_hit{instance="$instance"} / (pg_stat_database_blks_read{instance="$instance"} + pg_stat_database_blks_hit{instance="$instance"})
      legend: hit rate
    name: Cache hit rate
---
# Source: sentry/templates/ingest-replay-recordings-kafkatopic.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  labels:
    strimzi.io/cluster: kafka
  name: ingest-replay-recordings
  namespace: kafka
spec:
  config: {}
  partitions: 1
  replicas: 1
  topicName: ingest-replay-recordings
---
# Source: sentry/charts/rabbitmq/templates/rabbitmq-permission.yaml
apiVersion: rabbitmq.com/v1beta1
kind: Permission
metadata:
  name: release-name-rabbitmq
  labels:
    helm.sh/chart: rabbitmq-0.1.0
    app.kubernetes.io/name: rabbitmq
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  vhost: sentry
  userReference:
    name: release-name-rabbitmq
  permissions:
    configure: .*
    read: .*
    write: .*
  rabbitmqClusterReference:
    name: rabbitmq
    namespace: rabbitmq
---
# Source: sentry/charts/postgres/templates/prometheusrule.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    role: alert-rules
  name: sentry-postgres-rules
spec:
  groups:
  - name: sentry
    rules:
    - alert: sentryPostgreSQLCpuHigh
      expr: |
        (
          sum(rate(container_cpu_usage_seconds_total{namespace="default",pod=~"plural-sentry-[0-9]+"}[5m])) 
          / sum(kube_pod_container_resource_requests{endpoint="http",namespace="default", pod=~"plural-sentry-[0-9]+", resource="cpu"})
        )  > 0.6
      for: 5m
      labels:
        severity: warning
        namespace: default
      annotations:
        summary: sentry dbs's cpu usage has gotten too high
        description: the cpu utilization of your plural sentry is higher than recommended
    - alert: sentryPostgreSQLMemHigh
      expr: |
        (
          sum(container_memory_working_set_bytes{namespace="default",pod=~"plural-sentry-[0-9]+"})
          / sum(kube_pod_container_resource_requests{endpoint="http",resource="memory",namespace="default", pod=~"plural-sentry-[0-9]+"})
        )  > 1
      for: 5m
      labels:
        severity: warning
        namespace: default
      annotations:
        summary: sentry db's memory usage has gotten too high
        description: the memory utilization of your plural sentry db is higher than recommended
    - alert: sentryPostgreSQLMaxConnectionsReached
      expr: |
        sum by (instance) (pg_stat_activity_count{namespace="default",pod=~"plural-sentry-[0-9]+"})
        >=
        sum by (instance) (pg_settings_max_connections{namespace="default",pod=~"plural-sentry-[0-9]+"})
        -
        sum by (instance) (pg_settings_superuser_reserved_connections{namespace="default",pod=~"plural-sentry-[0-9]+"})
      for: 5m
      labels:
        severity: warning
        namespace: default
      annotations:
        summary: sentry db has maxed out Postgres connections
        description: "{{ $labels.instance }} is exceeding the currently configured maximum Postgres connection limit (current value: {{ $value }})."
    - alert: sentryPostgreSQLHighConnections
      expr: |
        sum by (instance) (pg_stat_activity_count{namespace="default",pod=~"plural-sentry-[0-9]+"})
        >
        (
          sum by (instance) (pg_settings_max_connections{namespace="default",pod=~"plural-sentry-[0-9]+"})
          -
          sum by (instance) (pg_settings_superuser_reserved_connections{namespace="default",pod=~"plural-sentry-[0-9]+"})
        ) * 0.8
      for: 5m
      labels:
        severity: warning
        namespace: default
      annotations:
        summary: sentry is over 80% of max Postgres connections.
        description: |
          {{ $labels.instance }} is exceeding 80% of the currently configured
          maximum Postgres connection limit (current value: {{ $value }}). Please check
          utilization graphs and confirm if this is normal service growth, abuse or
          an otherwise temporary condition or if new resources need to be provisioned
          (or the limits increased, which is mostly likely).
    - alert: sentryPostgreSQLDown
      expr: pg_up{namespace="default",pod=~"plural-sentry-[0-9]+"} != 1
      for: 1m
      labels:
        severity: warning
        namespace: default
      annotations:
        summary: sentry db is not processing queries.
        description: |
          {{ $labels.instance }} is rejecting query requests from the exporter,
          and thus probably not allowing DNS requests to work either. User services
          should not be effected provided at least 1 node is still alive.'
    - alert: sentryPostgreSQLSlowQueries
      expr: |
        avg by (datname) (
          rate (
            pg_stat_activity_max_tx_duration{namespace="default",pod=~"plural-sentry-[0-9]+",datname!~"template.*"}[2m]
          )
        ) > 2 * 60
      for: 2m
      labels:
        severity: warning
        namespace: default
      annotations:
        summary: sentry db has a high number of slow queries on {{ $labels.cluster }} for database {{ $labels.datname }}.
        description: PostgreSQL db has a high number of slow queries on {{ $labels.cluster }} for database {{ $labels.datname }}.
    - alert: sentryPostgreSQLQPS
      expr: |
        avg by (datname) (
          irate(
            pg_stat_database_xact_commit{namespace="default",pod=~"plural-sentry-[0-9]+",datname!~"template.*"}[5m]
          )
          +
          irate(
            pg_stat_database_xact_rollback{namespace="default",pod=~"plural-sentry-[0-9]+",datname!~"template.*"}[5m]
          )
        ) > 10000
      for: 1m
      labels:
        severity: warning
        namespace: default
      annotations:
        summary: sentry db has a high number of queries per second {{ $labels.cluster }} for database {{ $labels.datname }}.
        description: "sentry db has high a number of queries per second on {{ $labels.cluster }} for database {{ $labels.datname }} with a value of {{ $value }}."
    - alert: sentryPostgreSQLCacheHitRatio
      expr: |
        avg by (datname) (
          rate(pg_stat_database_blks_hit{namespace="default",pod=~"plural-sentry-[0-9]+",datname!~"template.*"}[5m])
          /
          (
            rate(
              pg_stat_database_blks_hit{namespace="default",pod=~"plural-sentry-[0-9]+",datname!~"template.*"}[5m]
            )
            +
            rate(
              pg_stat_database_blks_read{namespace="default",pod=~"plural-sentry-[0-9]+",datname!~"template.*"}[5m]
            )
          )
        ) < 0.98
      for: 1m
      labels:
        severity: warning
        namespace: default
      annotations:
        summary: sentry db has a low cache hit rate on {{ $labels.cluster }} for database {{ $labels.datname }}.
        description: "{{ .Values.ownerChart }} db has a low on cache hit rate on {{ $labels.cluster }} for database {{ $labels.datname }} with a value of {{ $value }}."
---
# Source: sentry/charts/postgres/templates/proxy.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: Proxy
metadata:
  name: db
  labels:
    helm.sh/chart: postgres-0.2.1
    app.kubernetes.io/name: postgres
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: db
  target: service/sentry-master
  credentials:
    secret: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
    key: password
    user: sentry
  dbConfig:
    name: sentry
    engine: postgres
    port: 5432
---
# Source: sentry/charts/clickhouse/templates/clickhouse-runbook.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: Runbook
metadata:
  name: release-name-clickhouse-scaling
  labels:
    platform.plural.sh/pinned: 'true'
    helm.sh/chart: clickhouse-0.1.2
    app.kubernetes.io/name: clickhouse
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "22.8.11.15"
    app.kubernetes.io/managed-by: Helm
spec:
  name: Release-Name Clickhouse Scaling
  description: Overview of how to optimally scale your ClickHouse cluster for Release-Name
  display: |-
    <root gap='medium'>
      <box pad='small' gap='medium' direction='row' align='center'>
        <button label='Scale' action='scale' primary='true' headline='true' />
        <box direction='row' align='center' gap='small'>
          <box gap='small' align='center'>
            <timeseries datasource="clickhouse-cpu" label="ClickHouse CPU Usage" />
            <text size='small'>You should set a reservation to 
              roughly correspond to 80% utilization</text>
            <text size='small'>A CPU limit should generally not be set</text>
          </box>
          <box gap='small' align='center'>
            <timeseries datasource="clickhouse-memory" label="ClickHouse Memory Usage" />
            <text size='small'>You should set a reservation to 
              roughly correspond to 80% utilization</text>
            <text size='small'>A Memory limit should be set</text>
          </box>
        </box>
        <box gap='small'>
          <box gap='xsmall'>
            <input placeholder="250m" label='ClickHouse CPU Request' name='clickhouse-cpu'>
              <valueFrom 
                datasource="clickhouse"
                doc="kubernetes.raw"
                path="spec.template.spec.containers[0].resources.requests.cpu" />
            </input>
            <input placeholder="1Gi" label='ClickHouse Memory Request' name='clickhouse-memory'>
              <valueFrom 
                datasource="clickhouse"
                doc="kubernetes.raw"
                path="spec.template.spec.containers[0].resources.requests.memory" />
            </input>
          </box>
          <box gap='xsmall'>
            <input placeholder="250m" label='ClickHouse CPU Limit' name='clickhouse-cpu-limit'>
              <valueFrom
                datasource="clickhouse"
                doc="kubernetes.raw"
                path="spec.template.spec.containers[0].resources.limits.cpu" />
            </input>
            <input placeholder="1Gi" label='ClickHouse Memory Limit' name='clickhouse-memory-limit'>
              <valueFrom
                datasource="clickhouse"
                doc="kubernetes.raw"
                path="spec.template.spec.containers[0].resources.limits.memory" />
            </input>
          </box>
        </box>
      </box>
      <box direction='row' align='center' gap='small'>
        <box gap='small' align='center'>
          <timeseries datasource="volume" label="ClickHouse Volume Usage" />
          <text size='small'>You should resize at around 80% utilization (or based on dataset growth)</text>
        </box>
        <box gap='small'>
          <input placeholder="20Gi" label='ClickHouse Volume Size' name='volume'>
            <valueFrom
              datasource="clickhouse"
              doc="kubernetes.raw"
              path="spec.volumeClaimTemplates[0].spec.resources.requests.storage" />
          </input>
        </box>
      </box>
    </root>
    
  datasources:
  - name: clickhouse-cpu
    type: prometheus
    prometheus:
      format: cpu
      legend: $pod
      query: sum(rate(container_cpu_usage_seconds_total{namespace="default",pod=~"chi-release-name-clickhouse-sentry-.*"}[5m])) by (pod)
  - name: clickhouse-memory
    type: prometheus
    prometheus:
      format: memory
      legend: $pod
      query: sum(container_memory_working_set_bytes{namespace="default",pod=~"chi-release-name-clickhouse-sentry-.*"}) by (pod)
  - name: volume
    type: prometheus
    prometheus:
      format: none
      legend: $persistentvolumeclaim
      query: (kubelet_volume_stats_capacity_bytes{namespace="default", persistentvolumeclaim=~"data-volumeclaim-template-chi-release-name-clickhouse-sentry-.*"} - kubelet_volume_stats_available_bytes{namespace="default", persistentvolumeclaim=~"data-volumeclaim-template-chi-release-name-clickhouse-sentry-.*"}) / kubelet_volume_stats_capacity_bytes{namespace="default", persistentvolumeclaim=~"data-volumeclaim-template-chi-release-name-clickhouse-sentry-.*"}
  - name: clickhouse
    type: kubernetes
    kubernetes:
      resource: statefulset
      name: chi-release-name-clickhouse-sentry-0-0
  actions:
  - name: scale
    action: config
    redirectTo: '/'
    configuration:
      updates:
      - path: 
        - release-name
        - clickhouse
        - resources
        - requests
        - cpu
        valueFrom: clickhouse-cpu
      - path:
        - release-name
        - clickhouse
        - resources
        - requests
        - memory
        valueFrom: clickhouse-memory
      - path: 
        - release-name
        - clickhouse
        - resources
        - limits
        - cpu
        valueFrom: clickhouse-cpu-limit
      - path:
        - release-name
        - clickhouse
        - resources
        - limits
        - memory
        valueFrom: clickhouse-memory-limit
      - path:
        - release-name
        - clickhouse
        - persistence
        - size
        valueFrom: volume
      # - path:
      #   - release-name
      #   - clickhouse
      #   - layout
      #   - shardsCount
      #   valueFrom: shards
---
# Source: sentry/charts/postgres/templates/runbook.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: Runbook
metadata:
  name: db-scaling
  labels:
    platform.plural.sh/pinned: 'true'
    helm.sh/chart: postgres-0.2.1
    app.kubernetes.io/name: postgres
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  name: Postgres Scaling
  description: overview of how to accurately scale sentry's postgres instance
  alerts:
  - name: sentryPostgreSQLCpuHigh
  display: |-
    <root gap='medium'>
      <box pad='small' gap='medium' direction='row' align='center'>
        <button label='Scale' action='scale' primary='true' headline='true' />
        <box direction='row' align='center' gap='small'>
          <box gap='small' align='center'>
            <timeseries datasource="cpu" label="CPU Usage" />
            <text size='small'>You should set a reservation to 
              roughly correspond to 30% utilization</text>
          </box>
          <box gap='small' align='center'>
            <timeseries datasource="memory" label="Memory Usage" />
            <text size='small'>You should set a reservation to 
              roughly correspond to 60% utilization</text>
          </box>
        </box>
        <box gap='small'>
          <box gap='xsmall'>
            <input placeholder="250m" label='CPU Request' name='cpu'>
              <valueFrom 
                datasource="statefulset" 
                doc="kubernetes.raw" 
                path="spec.template.spec.containers[0].resources.requests.cpu" />
            </input>
            <input placeholder="1Gi" label='Memory Request' name='memory'>
              <valueFrom 
                datasource="statefulset" 
                doc="kubernetes.raw" 
                path="spec.template.spec.containers[0].resources.requests.memory" />
            </input>
          </box>
          <box gap='xsmall'>
            <input placeholder="250m" label='CPU Limit' name='cpu-limit'>
              <valueFrom 
                datasource="statefulset" 
                doc="kubernetes.raw" 
                path="spec.template.spec.containers[0].resources.limits.cpu" />
            </input>
            <input placeholder="1Gi" label='Memory Limit' name='memory-limit'>
              <valueFrom 
                datasource="statefulset" 
                doc="kubernetes.raw" 
                path="spec.template.spec.containers[0].resources.limits.memory" />
            </input>
          </box>
        </box>
      </box>
      <box direction='row' align='center' gap='small'>
        <box gap='small' align='center'>
          <timeseries datasource="volume" label="Volume Usage" />
          <text size='small'>You should resize at around 80% utilization (or based on dataset growth)</text>
        </box>
        <box gap='small'>
          <input placeholder="25Gi" label='Volume Size' name='volume'>
            <valueFrom 
              datasource="statefulset" 
              doc="kubernetes.raw" 
              path="spec.volumeClaimTemplates[0].spec.resources.requests.storage" />
          </input>
        </box>
      </box>
      <box pad='small' gap='medium' direction='row' align='center'>
        <box direction='row' width='70%' align='center'>
          <text size='small'>You can also add more replicas to provide failover in case of outages, or optionally remove them to save cost</text>
        </box>
        <box direction='row' gap='small' width='30%' align='center'>
          <input datatype='int' placeholder="1" label='Replicas' name='replicas'>
            <valueFrom 
              datasource="statefulset" 
              doc="kubernetes.raw" 
              path="spec.replicas" />
          </input>
        </box>
      </box>
      <box width='100%' gap='small'>
        <text size='small'>Be sure to scale your postgres pods within your nodes capacities, listed here:</text>
        <table width='100%' datasource='nodes' path='nodes'>
          <tableColumn path='metadata.name' header='name' width='33%' />
          <tableColumn path='status.capacity.cpu' header='cpu' width='33%' />
          <tableColumn path='status.capacity.memory' header='memory' width='33%' />
        </table>
      </box>
    </root>
    
  datasources:
  - name: cpu
    type: prometheus
    prometheus:
      format: cpu
      legend: $pod
      query: sum(rate(container_cpu_usage_seconds_total{namespace="default",pod=~"plural-sentry-[0-9]+"}[5m])) by (pod)
  - name: memory
    type: prometheus
    prometheus:
      format: memory
      legend: $pod
      query: sum(container_memory_working_set_bytes{namespace="default",pod=~"plural-sentry-[0-9]+"}) by (pod)
  - name: volume
    type: prometheus
    prometheus:
      format: none
      legend: $persistentvolumeclaim
      query: (kubelet_volume_stats_capacity_bytes{namespace="default", persistentvolumeclaim=~"pgdata-plural-sentry-.*"} - kubelet_volume_stats_available_bytes{namespace="default", persistentvolumeclaim=~"pgdata-plural-sentry-.*"}) / kubelet_volume_stats_capacity_bytes{namespace="default", persistentvolumeclaim=~"pgdata-plural-sentry-.*"}
  - name: statefulset
    type: kubernetes
    kubernetes:
      resource: statefulset
      name: plural-sentry
  - name: nodes
    type: nodes
  actions:
  - name: scale
    action: config
    redirectTo: '/'
    configuration:
      updates:
      - path: 
        - sentry
        - postgres
        - resources
        - requests
        - cpu
        valueFrom: cpu
      - path:
        - sentry
        - postgres
        - resources
        - requests
        - memory
        valueFrom: memory
      - path: 
        - sentry
        - postgres
        - resources
        - limits
        - cpu
        valueFrom: cpu-limit
      - path:
        - sentry
        - postgres
        - resources
        - limits
        - memory
        valueFrom: memory-limit
      - path:
        - sentry
        - postgres
        - replicas
        valueFrom: replicas
      - path:
        - sentry
        - postgres
        - storage
        - size
        valueFrom: volume
---
# Source: sentry/templates/runbooks.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: Runbook
metadata:
  name: clickhouse-scaling
  labels:
    platform.plural.sh/pinned: 'true'
    helm.sh/chart: sentry-0.2.16
    app.kubernetes.io/name: sentry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "23.5.0"
    app.kubernetes.io/managed-by: Helm
spec:
  name: Clickhouse Scaling
  description: overview of how to accurately scale sentry's clickhouse cluster
  display: |-
    
  datasources:
  - name: cpu
    type: prometheus
    prometheus:
      format: cpu
      legend: $pod
      query: sum(rate(container_cpu_usage_seconds_total{namespace="default",pod=~"sentry-clickhouse-[0-9]+"}[5m])) by (pod)
  - name: memory
    type: prometheus
    prometheus:
      format: memory
      legend: $pod
      query: sum(container_memory_working_set_bytes{namespace="default",pod=~"sentry-clickhouse-[0-9]+"}) by (pod)
  - name: statefulset
    type: kubernetes
    kubernetes:
      resource: statefulset
      name: sentry-clickhouse
  - name: nodes
    type: nodes
  actions:
  - name: scale
    action: config
    redirectTo: '/'
    configuration:
      updates:
      - path: 
        - sentry
        - sentry
        - clickhouse
        - clickhouse
        - resources
        - requests
        - cpu
        valueFrom: cpu
      - path:
        - sentry
        - sentry
        - clickhouse
        - clickhouse
        - resources
        - requests
        - memory
        valueFrom: memory
---
# Source: sentry/templates/runbooks.yaml
apiVersion: platform.plural.sh/v1alpha1
kind: Runbook
metadata:
  name: volume-scaling
  labels:
    platform.plural.sh/pinned: 'true'
    helm.sh/chart: sentry-0.2.16
    app.kubernetes.io/name: sentry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "23.5.0"
    app.kubernetes.io/managed-by: Helm
spec:
  name: Clickhouse Volume Scaling
  description: overview of how to optimally scale your clickhouse persistent volumes
  display: |-
    <root gap='medium'>
      <box pad='small' gap='medium' direction='row' align='center'>
        <box direction='row' align='center' gap='small'>
          <box gap='small' align='center'>
            <timeseries datasource="clickhouse-volume" label="Clickhouse Volume Usage" />
            <text size='small'>You should probably give yourself at least 30% of headroom, depending on growth of usage</text>
          </box>
        </box>
        <box gap='small'>
          <box gap='xsmall'>
            <input placeholder="20Gi" label='Clickhouse Volume Size' name='clickhouse-storage'>
              <valueFrom
                datasource="clickhouse" 
                doc="kubernetes.raw" 
                path="spec.volumeClaimTemplates[0].spec.resources.requests.storage" />
            </input>
          </box>
          <box direction='row' justify='end'>
            <button label='Scale' action='volume-scale' primary='true' />
          </box>
        </box>
      </box>
    </root>
  datasources:
  - name: clickhouse-volume
    type: prometheus
    prometheus:
      format: none
      legend: $persistentvolumeclaim
      query: (kubelet_volume_stats_capacity_bytes{namespace="default", persistentvolumeclaim=~"sentry-clickhouse-data-.*"} - kubelet_volume_stats_available_bytes{namespace="default", persistentvolumeclaim=~"sentry-clickhouse-data-.*"}) / kubelet_volume_stats_capacity_bytes{namespace="default", persistentvolumeclaim=~"sentry-clickhouse-data-.*"}
  - name: clickhouse
    type: kubernetes
    kubernetes:
      resource: statefulset
      name: sentry-clickhouse
  actions:
  - name: volume-scale
    action: config
    redirectTo: '/'
    configuration:
      statefulSets:
      - name: sentry-clickhouse
        persistentVolume: sentry-clickhouse-data
        valueFrom: clickhouse-storage
      updates:
      - path: 
        - sentry
        - sentry
        - clickhouse
        - clickhouse
        - persistentVolumeClaim
        - dataPersistentVolume
        - storage
        valueFrom: clickhouse-storage
---
# Source: sentry/charts/sentry/templates/servicemonitor-metrics.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: release-name-sentry-metrics
  labels:
    app: release-name-sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
spec:
  endpoints:
    - port: metrics
      interval: 30s
  namespaceSelector:
    matchNames:
      - default
  selector:
    matchLabels:
      app: release-name-sentry-metrics
      release: "release-name"
      role: metrics
---
# Source: sentry/charts/rabbitmq/templates/rabbitmq-user.yaml
apiVersion: rabbitmq.com/v1beta1
kind: User
metadata:
  name: release-name-rabbitmq
  labels:
    helm.sh/chart: rabbitmq-0.1.0
    app.kubernetes.io/name: rabbitmq
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  tags:
    - management
  rabbitmqClusterReference:
    name: rabbitmq
    namespace: rabbitmq
---
# Source: sentry/charts/rabbitmq/templates/rabbitmq-vhost.yaml
apiVersion: rabbitmq.com/v1beta1
kind: Vhost
metadata:
  name: sentry
  labels:
    helm.sh/chart: rabbitmq-0.1.0
    app.kubernetes.io/name: rabbitmq
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  name: sentry
  rabbitmqClusterReference:
    name: rabbitmq
    namespace: rabbitmq
---
# Source: sentry/charts/postgres/templates/postgres.yaml
apiVersion: acid.zalan.do/v1
kind: postgresql
metadata:
  name: plural-sentry
  labels:
  
    helm.sh/chart: postgres-0.2.1
    app.kubernetes.io/name: postgres
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  teamId: plural
  volume:
    size: 25Gi
  numberOfInstances: 1
  users:
    sentry:  # database owner
    - superuser
    - createdb
  resources:
    limits:
      cpu: "2"
      memory: 1Gi
    requests:
      cpu: 100m
      memory: 100Mi
  databases:
    sentry: sentry  # dbname: owner
  postgresql:
    version: "14"
    
  sidecars:
  - image: gcr.io/pluralsh/prometheuscommunity/postgres-exporter:v0.12.0
    name: exporter
    resources:
       limits:
         cpu: 10m
         memory: 20Mi
       requests:
         cpu: 1m
         memory: 15Mi
    ports:
    - containerPort: 9187
      name: http-metrics
      protocol: TCP
    env:
    - name: "DATA_SOURCE_URI"
      value: "127.0.0.1:5432/sentry?sslmode=disable"
    - name: "DATA_SOURCE_USER"
      valueFrom:
        secretKeyRef:
          name: postgres.plural-sentry.credentials.postgresql.acid.zalan.do
          key: username
    - name: "DATA_SOURCE_PASS"
      valueFrom:
        secretKeyRef:
          name: postgres.plural-sentry.credentials.postgresql.acid.zalan.do
          key: password
---
# Source: sentry/charts/sentry/templates/hooks/sentry-db-check.job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-sentry-db-check
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "hook-succeeded,before-hook-creation"
    "helm.sh/hook-weight": "-1"
spec:
  activeDeadlineSeconds: 600
  template:
    metadata:
      name: release-name-sentry-db-check
      annotations:
      labels:
        app: sentry
        release: "release-name"
    spec:
      restartPolicy: Never
      containers:
      - name: db-check
        image: gcr.io/pluralsh/library/busybox:1.36.0
        imagePullPolicy: IfNotPresent
        command:
          - /bin/sh
          - -c
          - |
            echo "Checking if clickhouse is up"
            CLICKHOUSE_STATUS=0
            while [ $CLICKHOUSE_STATUS -eq 0 ]; do
              CLICKHOUSE_STATUS=1
              CLICKHOUSE_REPLICAS=1
              i=0; while [ $i -lt $CLICKHOUSE_REPLICAS ]; do
                CLICKHOUSE_HOST=service-sentry-clickhouse
                if ! nc -z "$CLICKHOUSE_HOST" 9000; then
                  CLICKHOUSE_STATUS=0
                  echo "$CLICKHOUSE_HOST is not available yet"
                fi
                i=$((i+1))
              done
              if [ "$CLICKHOUSE_STATUS" -eq 0 ]; then
                echo "Clickhouse not ready. Sleeping for 10s before trying again"
                sleep 10;
              fi
            done
            echo "Clickhouse is up"

            echo "Checking if kafka is up"
            KAFKA_STATUS=0
            while [ $KAFKA_STATUS -eq 0 ]; do
              KAFKA_STATUS=1
              KAFKA_HOST=kafka-kafka-bootstrap.kafka
              if ! nc -z "$KAFKA_HOST" 9092; then
                KAFKA_STATUS=0
                echo "$KAFKA_HOST is not available yet"
              fi
              if [ "$KAFKA_STATUS" -eq 0 ]; then
                echo "Kafka not ready. Sleeping for 10s before trying again"
                sleep 10;
              fi
            done
            echo "Kafka is up"
        env:
        resources:
          limits:
            memory: 64Mi
          requests:
            cpu: 100m
            memory: 64Mi
---
# Source: sentry/charts/sentry/templates/hooks/sentry-db-init.job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-sentry-db-init
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "hook-succeeded,before-hook-creation"
    "helm.sh/hook-weight": "6"
spec:
  activeDeadlineSeconds: 600
  template:
    metadata:
      name: release-name-sentry-db-init
      annotations:
        checksum/configmap.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: sentry
        release: "release-name"
    spec:
      restartPolicy: Never
      containers:
      - name: db-init-job
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["sentry","upgrade","--noinput"]
        env:
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        resources:
          limits:
            memory: 2048Mi
          requests:
            cpu: 300m
            memory: 2048Mi
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
---
# Source: sentry/charts/sentry/templates/hooks/snuba-db-init.job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-sentry-snuba-db-init
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "hook-succeeded,before-hook-creation"
    "helm.sh/hook-weight": "3"
spec:
  activeDeadlineSeconds: 600
  template:
    metadata:
      name: release-name-sentry-snuba-db-init
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: sentry
        release: "release-name"
    spec:
      restartPolicy: Never
      containers:
      - name: snuba-init
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        command: [snuba, bootstrap, --no-migrate, --force]
        env:
        - name: LOG_LEVEL
          value: debug
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        resources:
          limits:
            cpu: 2000m
            memory: 1Gi
          requests:
            cpu: 700m
            memory: 1Gi
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/hooks/snuba-migrate.job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-sentry-snuba-migrate
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "hook-succeeded,before-hook-creation"
    "helm.sh/hook-weight": "5"
spec:
  activeDeadlineSeconds: 600
  template:
    metadata:
      name: release-name-sentry-snuba-migrate
      annotations:
        checksum/snubaSettingsPy: d5f85a6a8afbc55eebe23801e1a51a0fb4c0428c9a73ef6708d8dc83e079cd49
        checksum/config.yaml: 5dc0895c3471ccd690163eaa7a7d1c42a902494e632790baf5d64f691567fd54
      labels:
        app: sentry
        release: "release-name"
    spec:
      restartPolicy: Never
      containers:
      - name: snuba-migrate
        image: "dkr.plural.sh/sentry/getsentry/snuba:23.5.0"
        command: [snuba, migrations, migrate, --force]
        env:
        - name: LOG_LEVEL
          value: debug
        - name: SNUBA_SETTINGS
          value: /etc/snuba/settings.py
        - name: DEFAULT_BROKERS
          value: "kafka-kafka-bootstrap.kafka:9092"
        envFrom:
        - secretRef:
            name: release-name-sentry-snuba-env
        volumeMounts:
        - mountPath: /etc/snuba
          name: config
          readOnly: true
        resources:
          limits:
            cpu: 2000m
            memory: 1Gi
          requests:
            cpu: 700m
            memory: 1Gi
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-snuba
---
# Source: sentry/charts/sentry/templates/hooks/user-create.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-sentry-user-create
  labels:
    app: sentry
    chart: "sentry-19.0.0"
    release: "release-name"
    heritage: "Helm"
  annotations:
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "hook-succeeded,before-hook-creation"
    "helm.sh/hook-weight": "9"
spec:
  activeDeadlineSeconds: 600
  template:
    metadata:
      name: release-name-sentry-user-create
      annotations:
        checksum/configmap.yaml: c5a37d83635b85642001cd80427de5576c67dc85db5f13567789cad2d423bb5d
      labels:
        app: sentry
        release: "release-name"
    spec:
      restartPolicy: Never
      containers:
      - name: user-create-job
        image: "dkr.plural.sh/sentry/getsentry/sentry:23.5.0-plural3.0.0"
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash", "-c"]
        # Create user but do not exit 1 when user already exists (exit code 3 from createuser command)
        # https://docs.sentry.io/server/cli/createuser/
        args:
          - >
            sentry createuser \
              --no-input \
              --superuser \
              --email "admin@sentry.local" \
              --password "$ADMIN_PASSWORD" || true; \
            if [ $? -eq 0 ] || [ $? -eq 3 ]; then \
              exit 0; \
            else \
              exit 1; \
            fi
        env:
        - name: SNUBA
          value: http://release-name-sentry-snuba:1218
        - name: SENTRY_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentry-system-secret
              key: key
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sentry.plural-sentry.credentials.postgresql.acid.zalan.do
              key: password
        - name: ADMIN_PASSWORD
          value: "aaaa"
        volumeMounts:
        - mountPath: /etc/sentry
          name: config
          readOnly: true
        resources:
          limits:
            memory: 2048Mi
          requests:
            cpu: 300m
            memory: 2048Mi
      volumes:
      - name: config
        configMap:
          name: release-name-sentry-sentry
